---
{"banner":"zob_config/banners/013.jpg","create":"2023-07-12","update":"2023-07-12","status":["待完成"],"publish":false,"priority":1,"aliases":["未命名"],"tags":null,"dg-path":"Redis/📑 Redis--索引笔记--Redis面试题","dgPassFrontmatter":true,"noteIcon":"","dg-publish":true,"permalink":"/Redis/📑 Redis--索引笔记--Redis面试题/"}
---


>Redis 的高级功能的核心: 是否会阻塞主线程!!!


### Redis 为什么执行那么快
#面试重点复习
>我们常说 Redis 是单线程的, 但是实际上怎么可能呢, 如果全部都是单线程的, 比如持久化, 集群数据同步, 怎么实现.
>- 所以说我们说的单线程, 指的是 Redis 的键值对读写是由一个线程来完成的, 这也就是我们经常使用到一个操作.
>- 就是 key 是存储在 Hash 表中的, 插入和删除是非常快的, 底层 Hash 表是通过一个字典实现的, ==然后字典保存 RedisObject, 然后这相当于 Java 中的包装类的感觉, 就说内部通过一个通用指针来实现保存不同的数据, void * 指针是通用指针, redisObject 中的 type 属性保存其类型, 这让我们可以操作和识别类型==
>- Redis 中的其他操作, 比如说持久化, 异步删除, 集群数据同步. 这些都是由额外的线程去执行的.
>- 除了单线程, 还有一个很重要的原因, Redis 的操作是基于内存的, 再加上它采用了高效的数据结构, 比如说哈希表, 跳表, 压缩列表, 并且基本上都实现了多种方式, 用来适用于少量/大量的数据存储, 并且对于较小的内容, 一般都有单独的编码类型, 用于适配缓存行, 这类类型通常都会极致压缩内存, 而较大的话, 则不会极致压缩性能, 则会均衡考虑其使用效率来设计
>- Redis 采用了多路复用机制, 使得网络 IO 操作中能并发处理大量的客户端请求, 实现高吞吐量 [[Tomcat总览\|Tomcat总览]],里面的 Connector 也采用的多路复用机制.
>- **基于事件驱动模型, 用事件驱动模型+回调函数实现了异步非阻塞模型, 底层是 NIO**
>- 其他的小细节: 例如存储共享对象, 不够只支持整数; refCount 保存对象的空转时长, 可以用来快速的删除元素 ; 每种数据结构都存在多种的编码, 就是极其的扣内存, 非常厉害,, 其编码的特点我有注意到, 很多数据结构在数据特别少的情况下, 都会使用压缩列表, 为什么呢, 因为压缩列表, 不存在指针, 甚至连数组信息保存的都很少, 在查询数据的过程中, 很多元素内容都存放到 CPU 的高速缓存中了, 所以说性能是很快的, 当数据内容很多的时候, 就不使用压缩列表了, 比如说 List 就是用了链表, 因为虽然压缩列表访问起来是 ON 的时间复杂度**不够这里的 ON 大部分时候, 我觉得并不能看作 ON, 因为它设计来就是为了保存少量的数据, 而且保存了末尾节点距离起始位置的字节数, 是可以进行顺序/逆序的搜索, O n/2 比较合适**, 但是耐不住 CPU 高速缓存很牛逼啊 (类似于跟一个瘸子比跑步, 但是瘸子是开车跟你跑的啊), 当数据内容很多很长, 就使用了链表的结构, 性能也会比较好, 插入节点, 删除节点很方便
>- 尽快优化可能阻塞的地方



### Redis 的另一个大特点-高可用
>高可用的话, 主要是其主从库读写分离, 哨兵机制选举以及维护 Redis 集群


### Redis 的多路复用机制
>基于 slelect/epoll 机制, Redis 在运行单线程的情况下, 运行同时存在多个监听的套接字和已连接的套接字. 然后操作系统去监听链接请求和数据请求, 然后交给 Redis 来处理, 这才实现了一个 Redis 线程处理多个 IO 流的效果
>
>
> ![Pasted image 20230226101634.png](/img/user/zob_attach/Pasted%20image%2020230226101634.png)
>由图, 可以看见, Redis 监听套接字, 然后对于不同的事件, 都加入到事件处理队列中, 然后事件出队的时候, 触发 Redis 的响应事件回调函数, 比如如果是读取事件, 就调用 get, 写事件就调用 put.
>如果用现实例子, 比较像医院, 医院有分诊台, 就是比如我们也可以随便的去问一个医生, 如果我脚受伤了, 腿受伤了, 该去哪, 他们的作用就减少医生的诊断工作, 然后分到不同的医生那去.



### Redis 的事件驱动模型
通过事件循环 EventLoop 和回调函数来实现的, 在 Redis 中, 事件循环时 Redis 的主线程, 一旦有事件发送, 就会调用相应的回调函数来啊处理事件.
IO 多路复用使得其能够同时监听很多个连接, 请求.



### 为什么 Redis 不是多线程的
>首先多线程必然会出现线程安全问题, 这就需要去进行一个精细的控制才能保证线程安全的情况下提升性能.
>比如说 Redis 中的集合类型, 比如说压缩列表, 双向列表, 整数数组等, 其实都是有记录元素的, 假如存在多线程, 这个计数很可能就不准了.
>除此之外, 为了保证线程安全, 必然就需要加锁或者 CAS, 加锁阻塞严重, 加 CAS, 内存消耗严重, Redis 是面向于高并发的, 阻塞并不是我们想要的.
>缓存是为了什么, 减少数据库的 IO 链接, 很大情况下, 我们会去缓存热点数据, 即使我们只加写锁, 那么写数据的时候特别是写入一个大 Key, 可能会立刻堆积大量的请求, 导致大量的请求被阻塞住. 这是比较严重的.


### 你对 Redis 中新增的多线程部分了解吗
>了解一点点, 使用 Redis 肯定都会听说过嘛
>之前一直没有使用多线程. 是因为
>1. 本身数据结构就已经优化的很不错了, 包括内存使用等等各个方面
>Redis 引入多线程, 是为了提高网络 IO 的独读写性能, 并且引入多线程之后, 键值对读写等操作, 仍然是一个单线程执行模式.


### Redis 中有哪些操作时
RDB 持久化 : 拷贝父线程的页表, 然后对要


### 有哪些因素可能会影响到 Redis 的速度
>如果要说因素的话, 我们应该从为什么那么快来思考, 一个特点能让他变快, 那么如果特点没有发挥出来, 也会让他变慢.
>哈希表冲突问题严重, rehash 的时候, 查询会变得慢一些 (先从新的哈希表找)
>基于哈希表的存储, 也会有冲突问题, 让 o 1 变成 on 
>单个请求耗时较长, 影响后面的所有请求,
>	操作 bigKey 
>	对集合进行 get all


### Redis 的可靠性如何保证/Redis 在断电后数据会消失, Redis 怎么保证数据不被丢失的
>1. 基于内存, 断电数据消失
>	最有效的办法是, 不让他断电, 就和 Redis 中的事务一样, 开启事务的时候, 如果发生了语法错误, 那么事务是不会回滚的, 这个最好的操作也是不让他发生语法错误.
>	其次..... Redis 是有持久化的部分的 [[2 知识库/1 数据库/Redis/索引笔记/📑 Redis--索引笔记--Redis面试题#AOF\|#AOF]] [[2 知识库/1 数据库/Redis/索引笔记/📑 Redis--索引笔记--Redis面试题#RDB\|#RDB]]


### Redis 是二进制安全的 (有趣)
>我们面向流进行交互的时候, 都分为字符流和字节流, 当通过 Socket 访问 Redis 的时候, 我们是使用字节流而不是字符流, 这样 Redis 只需要专注于存储字节就可以了, 另一方可以根据之间制定的编码集就可以获取数据了.
>字符流需要基于特定的一个编码集才能转换.


### Redis 不适用的场景
>1. 直接查询 value:
>2. 多个 key 指向同一个 value
>3. 事务回滚: 不支持, 并且不能有语法错误, 除非使用 watch, 类似于条件事务


### Redis 的应用场景
#面试重点复习
>1. 缓存: 在访问 DB 之前, 去将热点数据缓存到 Redis 中, 减少数据库的压力. 这个操作的话, 我联想到了就是操作系统中的高速缓存, 每个 CPU 都有高速缓存, 持有主内存副本. 高速缓存能够减少大量原本发向内存的请求
>2. 提高系统响应: 因为数据库属于 IO, 是需要读磁盘的. 但是如果从 redis 中读取信息, 那么就是从内存中直接返回, 根据操作系统的存储器分级策略, 内存属于高于磁盘的一级, 交互更快.
>3. 做 Session 分布式: Tomcat 底层是使用 Session 的, 但是但使用分布式之后呢, Tomcat 的 Session 无法共享, Tom act 也有 Session 复制的功能, 但是很多个 Tomcat 之间互相复制, IO, 很消耗内存
>4. 分布式锁: 解决分布式中的"线程安全问题"
>5. 乐观锁: 使用 watch + incr 实现乐观锁



### 简要介绍一下 Redis
>Redis 是一个由 C 语言的, Key-Value 键值对非关系缓存数据库. 支持 String 类型 (包括整数和浮点数), list 链表, set 集合, sortedset 等数据结构
>Redis 是基于内存的, 所以说很快
> [[2 知识库/1 数据库/Redis/索引笔记/📑 Redis--索引笔记--Redis面试题#Redis为什么执行那么快\|#Redis为什么执行那么快]]
> [[2 知识库/1 数据库/Redis/索引笔记/📑 Redis--索引笔记--Redis面试题#Redis的应用场景\|#Redis的应用场景]]
>并且 Redis 支持事务, 对数据的更高要么全部执行, 要么就不执行, 但是 Redis 的事务属于很简单的事务, 甚至不支持错误回滚.



### 常用命令
>exist 判断 key 是否存在
>del 删除 key
>type 判断 key 类型
>ttl 查看 key 存活时间



#### Redis 如何使用事务
>开启事务:multi
>执行事务:exex
>取消事务:Discard
>不过 Redis 的事务功能很单一, 有些情况下事务不会回滚
>1. 语法错误导致事务执行异常 (命令不存在), 事务会取消, 但是语法异常之前.
>2. 运行时错误 (比如说命令使用不正确), 比如说对 String 执行 lpush
>Redis 不支持事务可能是因为大多是失败都是因为语法错误, 即用户的错误. Redis 为了提高性能就没有做回滚
>但是我们可以使用 watch 和事务语句来让事务具有条件回滚功能
>使用 watch 监听某个 key, 然后开启事务, 然后执行语句, 然后关闭事务, 事务会回滚, 也就是说 watch 之后开启事务, 只要监听的值变化, 事务提交就得回滚.
>使用 unwatch 可以取消监控


### 你对 Redis 的事务有什么了解
>我觉得使用 Redis, 我们要求并不是强或者说比较强的数据一致性, 因为我们要求的是其给性能带来的提升, 而是不保证 Redis 数据的一致性.
>为什么不要求一致性呢?, 因为我们都是以 MySQL 数据为准嘛, 而 Redis 和 MySQL 如果跨主机了, 要保证数据的一致性就非常的困难, 至少会极大损耗性能, 这不是我们引入 Redis 想要的结果.
>Reids 本身就没有去按照很高的数据一致性去设计: 比如说 MySQL 的 WAL 写前日志可以解决断电的时候出现的问题, 双写缓冲区也是为了刷盘时出现故障, 他们都是保证数据一致性的. 但是来看看 Redis 写后日志 (保护性能, 加快读写速度), 三种持久化策略, 只有一种是能够保护数据一致性的 (还很耗费性能), 内存不够了, 还是会淘汰. 假如是分布式, 也存在很多问题会导致数据不一致性!!

### Redis 的 Key 可以为哪些类型
>

### Redis 常见的数据结构 
![Pasted image 20230226093854.png](/img/user/zob_attach/Pasted%20image%2020230226093854.png)
[[压缩列表\|压缩列表]] 
[[Redis---SkipList编码\|Redis---SkipList编码]]

![Pasted image 20230226095815.png](/img/user/zob_attach/Pasted%20image%2020230226095815.png)
压缩列表和整数数组, 都是采用一个非常紧凑的方式去保存数据, 都没有使用指针去连接, 更节省内存.
双向链表虽然有指针, 但是如果数据量很大的情况下, 使用起来查找速度会快一点

[[Redis---String类型\|Redis---String类型]]
>分布式 session
>分布式数据库 ID
>ji'shu

[[Redis---List类型\|Redis---List类型]]
>基础操作:
> [[02数据结构：快速的Redis有哪些慢操作？_一手IT课程资源+微信2268731.pdf]]
>	单元素操作:  O 1, 但是如果是一次操作 M 个数据, 就变成了 OM
>	范围操作: 遍历操作, 为 ON, 很耗时, 尽量避免
>	统计操作: 因为各种结构都存储了个数, 所以说 O 1
>实现队列, 栈操作, 因为对于两端数据, 都有 pop push 的功能, 如 lpop, rpop, lpush, rpush
>汇总日志
>粉丝列表 
>关注的人列表

[[Redis---Hash类型\|Redis---Hash类型]]
>他给我的感觉就, 类似于 Map<String, String>
>存储对象信息 (例如购物车商品, 热门商品)


[[Redis---Set类型\|Redis---Set类型]]
>签到
>打卡
>点赞


[[Redis---sortedset有序集合类型\|Redis---sortedset有序集合类型]]


[[📑 Redis--永久笔记--HyperLogLogs类型\|📑 Redis--永久笔记--HyperLogLogs类型]]
>基数统计

bitmaps
>统计用户访问次数


### Redis 如何保存所有的 Key
#面试题/精 
>首先是基于 Hash 表来存储所有的 k-v 的,
>但是如果你只想到这里, 还会有很多问题的?
>比如说集合类型, 如何我们的 v 是一个集合, 也就是说怎么保存数组?
> 其实，哈希桶中的元素保存的并不是值本身，而是指向具体值的指针。[[02数据结构：快速的Redis有哪些慢操作？_一手IT课程资源+微信2268731.pdf]]
> ![Pasted image 20230226094300.png](/img/user/zob_attach/Pasted%20image%2020230226094300.png)
>看着这个图，其实 Redis 的哈希表, 我认为就跟 HashMap 几乎一样, 多个元素下是使用链表的结构

### Redis 的哈希表冲突和 rehash 问题
>要涉及这一个东西, 最重要的还是考虑如何避免阻塞主线程
> 问题阐述:
> 	当插入的数据过多, 哈希表就越容易出现冲突问题, 当过多之后, 如果需要扩容, 扩容之后也需要考虑 rehash 的问题了
> 解决办法:
> 	Redis 是默认使用了两个全局 hash 表 (rehash 的时候使用新线程去创建并渐进), 这个做法的形式是很像 [[Survivor区\|Survivor区]] 和 [[Eden区\|Eden区]],那两个区是因为如果只扫描一个 s 和 eden, 然后减少内存碎片的产生.
> 	再讲回来, 如何操作的呢?
> 	1. 给 hash 表 2 分配更大的空间
> 	2. 然后把 hash 表 1 数据重新映射到哈希表2中
> 	3. 释放哈希表 1 的空间
> 	但是看似这个过程简单, 但是涉及了大量的数据拷贝问题, 如果一次性把哈希表 1 的数据都迁移, 会产生线程阻塞, 因为 Redis 的网络 Io 和键值对读写都是单线程的, 数据都被迁移了, 线程必然阻塞.
> 	为了避免这个问题，Redis 采用了渐进式 rehash。[[02数据结构：快速的Redis有哪些慢操作？_一手IT课程资源+微信2268731.pdf]]
> 	1. 在原先的第二步进行优化
> 	2. 当需要 rehash 的时候, 每次处理一个请求, 就从哈希表第一个位置开始, 讲所有的 entries 拷贝到哈希表2中
> 	3. 这里的理念就是, 将开销分布到 n 个请求之上
> ==rehash 的时候如果有新数据插入, 直接到新表. 查询操作是先新表, 后旧表, 因为数据可能是新插入的, 并且如果不是新插入的, 新表没有, 可能是没有转移过来, 此时旧表有数据. 如果不是新插入的==


### Redis 数据类型结构 


### 为什么不实用 Map/Guava 做缓存
>因为缓存也分为本地缓存和分布式缓存, Java 自带的 Map 或者 Guava 实现的都是本地缓存, 最主要的特点就是轻量和快速, 生命周期随着 JVM 的销毁而结束, 最重要的应该是缓存具有不一致性.
>实用 Redis 的话, Redis 是分布式缓存, 多实例情况下, 公用一份缓存数据.


### 缓存雪崩
#面试重点复习
>缓存雪崩: 当缓存服务器重启或者大量缓存集中在一个时间段失效, 失效的时候, 会给后端带来很大的压力.==大量的 Key 失效==
>比如大量的 key 突然失效或者 redis 重启, 大量访问数据库, 数据库崩溃
>解决办法:
>1. 让 key 的失效期分散开, 不同的 key 尽可能设置不同的有效期

### 缓存击穿
#面试重点复习
>缓存在某个时间点过期的时候, 恰好对这个 key 有大量并发的请求过来, 发现缓存过期之后, 一般都会从后端 DB 加载数据然后回设到 Redis 中, 但是这个时候高并发可能把后端 DB 压垮
>解决办法:
>1. 限流操作：保护后端的安全
>2. 使用布隆过滤器预加载数据 : 布隆过滤可以肯定数据是否不存在

### 缓存雪崩和缓存击穿的区别
>前者是大量的数据同时失效或者过期导致的, 而后者是某个数据过期了, 并且有大量并发数据发送过来, 然后全部落到后端中

### 缓存穿透
#面试重点复习
>在高并发情况下, 查询不存在的 key, 会穿过 Redis 直接查询数据库, 导致数据库压力过大而宕机.
>解决办法:
>2. 在缓存之前, 加一层布隆过滤器, 查询的时候先去布隆过滤器查询 key 是否存在, 如果不存在就直接返回, 存在再查缓存和 DB
>3. 通过限流、验证码等操作，防止此类的请求频繁进入
>4. 缓存异常数据、空对象，如果布隆过滤器查不到就返回


### Redis 中的可达性分析
[[可达性分析\|可达性分析]]
对于可达性分析, 其按理说速度会很快, 但是要维护计数器线程安全, 往往就需要加锁.
但是 Redis 中的键值对操作是单线程的, 不需要控制线程安全, 所以说 Redis 中的 redisObject 中就保存了一个 refCount, 这样当计数器为 0 的时候, 就代表



### HotKey 问题
>大量的请求访问某个 Redis 某个 Key 的时候, 由于网络几种达到网络上限, 导致这个 redis 服务器宕机, 造成缓存击穿, 然后接下来直接访问数据库造成数据库崩溃.
>如何解决:
>1. 提前预估热 key, 比如秒杀啊, 活动, 变分布式缓存为本地缓存。
>2. 在主节点上提前备份热 key, 然后读取的时候将请求分布到每个 Redis 之上
>3. 限流熔断保护措施: 限制每个 Redis 最高的读取次数, 如果超过, 就返回



### 什么是缓存降级
>当访问量剧增,服务出现问题 (比如响应事件慢或者不响应), 此时我们需要保证服务是可以用的, 就需要对一些关键数据进行自动降级.
>缓存降级的目的是保证核心服务可用

### 淘汰和删除策略根据什么来删除
>redisObject 中有一个 lru 字段, 标识了该数据的空转时间







### 如何解决数据不一致的问题


### AOF
>不同于数据库的 WAL, 写前日志, AOF 是写后日志, 即命令执行完之后才记录日志, 不会阻塞当前的写操作.
>写前日志的好处是: 如果命令没有执行, 可以从日志来更新, 但是反之, 如果命令执行了, 日志没有更新, 就糟了
>写后日志, 就是性能方面的好处
>AOF 既然是写后日志, 会存在一个问题, 如果没有记记日志就宕机了, 就会无法恢复, 但是好在 Redis 是用来进行缓存的, 可以重新读取, 但是如果是数据库, 确实也就无法恢复了. Redis 提供了三个策略,
>	Alwa: 每个写命令执行完, 就立刻写日志, 立刻写入磁盘
>		*影响性能, 可靠性高*
>	Eversec: 每秒写回, 每次命令写完先写日志, 在写入磁盘
>		*减少了性能开销, 但是会有比较多的数据丢失, 性能适中*
>	No: 操作系统决定何时将 AOF 日志写入磁盘
>		*性能好, 但是丢失数据很多*

### AOF 重写流程
>重写其实不难, 就是从数据库读取键值对的状态, 比如说原来两条操作 String 的语句, 其实只需要获取当前数据库该 String 的状态即可.
>AOF 是后台重写的, 即 fork 一个子线程, 然后使用写时复制来进行后台的访问数据

**这个名称有点误导, 重写不会去修改 AOF 文件, 甚至不会访问 AOF 文件, 而是创建一个新的文件保存的是数据库当前的状态**

在 AOF 重写过程中，Redis 会使用管道将内存中的数据批量写入新的 AOF 文件，而不是逐条写入。这样可以减少磁盘 IO 的次数，提高写入性能。同时，由于管道可以一次性发送多个命令，还可以减少网络通信的延迟。

### RDB

### 内存快照: 如何实现快速恢复
[[05内存快照：宕机后，Redis如何实现快速恢复？_一手IT课程资源+微信2268731.pdf]]
>AOF 的操作是, 记录命令, 然后如何宕机了, 逐一执行之前的 AOF 命令, 这个劣势就是如果操作日志多, 那么恢复就会很慢.
>然后就出现了 RDB, RDB 原理就是内存快照, 记录某一个时刻数据状态, 但是这个时候是有两个问题的, 就是, 如果确定快照的数据范围, 多久快照一次, 如果范围过大, 必然耗费内存.
>==最重要的问题依然是, 是否会阻塞主线程 ==
>	不会, 我们可以采用创建子进程的方式来写入 RDB 文件, 通过 fork 父线程的页表, 子线程能拥有父线程的数据, 当我们快照一块区域的时候, 会使用一个写时复制的技术, 如果主线程要修改一块区域的时候, 这块区域生成一个副本, 子线程对副本进行快照写入 RDB, 这样不会造成线程安全问题.
> [[05内存快照：宕机后，Redis如何实现快速恢复？_一手IT课程资源+微信2268731.pdf]]
>	可以做增量快照, 全局快照一次之后, 每次就只对其进行增量快照
>	或者是 AOF+RDB 的方式, 就是内存快照以一定的频率执行, 然后快照之间使用 AOF 记录.*好处就是 AOF 一般不会太大, 内存快照也不会太频繁*

### 传递 RDB 的流程
1. 通过 slaveof 建立主从关系
2. 建立套接字连接
3. 发送 PING 命令
4. 开始同步, 客户端发送 sycn 命令, 清空客户端数据, 服务器 fork 一个子线程, 然后快照一个 RDB 文件, 然后发送给客户端.
	1. 即一开始属于全量复制, 但是这个步骤很费性能
	2. 假如断线, 并且时间不长, 采用的是增量复制, 就是把断线期间的命令发送过去, 因为两端各维护一个缓冲区和偏移量, 偏移量代表发送的数据, 如果偏移量不一样, 那么就说明少了多少字节未同步. 由客户端发送 pysync + offset ,服务器即可单独发送这部分数据. 
	3. 注意如果断线时间长, 数据不在缓冲区内, 就只能采用全量复制了
5. 命令传播
>缓冲区大小为 1 M, 如果有需要, 可以设置成 second * write_size_ptr_second 来设置缓冲区大小, 建议设置为服务器断线后重连所需时间 * 每秒写入数据量

### RDB 和 AOF
>数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择；
如果允许分钟级别的数据丢失，可以只使用 RDB；
如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个
平衡。


### 绑核问题
[[17为什么CPU结构也会影响Redis的性能？_一手IT课程资源+微信2268731.pdf]]


### 介绍一下 Redis 的 ACID
流程:
1. 事务开启
2. 命令入队
3. 事务执行 

>首先使用 multi 开启事务, 然后就可以输入命令了, 这里要注意的是, 如果是数据操作语句, 那么就会先入队, 而不执行, 等到最后 Exec 的时候才会执行.
>我们可以在事务开启前, 使用 watch 监视一个 Key, 就加入到 watched_keys 字典中, 其中值为一条标识, 如果该标识开启, 那么就代表被修改了, 事务无法执行.


>**原子性 A:** 我觉得可能是不能保证原子性的, 或者说勉强能达到原子性, 但是书上说的是能够保证原子性. 我觉得在 MySQL 中, 是通过 undoLog 来保证原子性的, 会使用到回滚, 即使是断电了, 也能保证事务的原子性. 而 Redis 中, 能保证原子性的前提是, 我们的命令在执行期间不出现错误, 如果出现错误, 就没有原子性了
>**一致性 C**: 能够完成其他三个才算一致性, 而这里的话, 也只能算勉强有一致性, 因为可能会存在执行错误, 和服务器停机的问题, 不过要注意的是, 服务器停机之后, 空白的数据库也是有一致性的, 但是此时事务就不具有原子性了, 如果开启了持久化, 也可以通过 RDB 来恢复, 然后恢复一致性, 但是原子性可能也没有保证.
>**隔离性 I**: Redis 是单线程的, 保证了执行事务的时候, 不会对事务进行中断, 事务可以执行到所有事务中的命令执行完成, 所有是有隔离性的.
>**持久性 D**：事务本身是没有持久性的，但是由于 Redis 是有持久化配置来决定是否进行数据的持久化的, 包括基于快照的 RDB 和基于命令的 AOF



### Redis 的事务操作
>通过四个命令实现 multi , exec discard watch 来实现
>1. redis 不支持回滚, 如果因为语法错误导致事务失败, 仍然会执行剩下的命令, 造成数据不一致性 
>2. 如果一个事务中的命令出现错误



### Redis 主从库如何保证数据一致性
[[06数据同步：主从库如何实现数据一致？_一手IT课程资源+微信2268731.pdf]]
>如何做到高可靠性? 有两个点, 一个是要保证数据尽量少丢失, 这一点是由 AOF 和 RDB 来保证的, 而第二点是让服务尽量少宕机导致不可用.


## 集群

### Redis 主从架构
>最重要的一点, 单机是无法保证高可用的, 所以使用 Redis 就可以采用这样的一种主从架构, 当一个节点宕机的时候, 也能够整个访问, 并且如果是主节点宕机了, 也会通过选举机制来选举出新的主节点.
>主从节点之间通过主从复制来进行数据的同步. 保证数据的一致性问题, 所有的读请求就走从节点, 所有的写操作就到主节点.
> ![Pasted image 20230226215536.png](/img/user/zob_attach/Pasted%20image%2020230226215536.png)
>作用:
>	读写分离:
>		一主多从, 主从同步
>		主节点负责写, 从节点负责读
>	


### 切片集群/为什么要切片
#url/redis  https://mp.weixin.qq.com/s/Q68UN34-BqxyQFtkJL98lg ：为什么用哈希槽，而不是一致性哈希。
>在集群结构下, 如果需要保存大量数据, 并且如果每个节点都保存全部数据, 那么就会有一个问题, 每个节点都需要很多的内存, 这会提高成本.
>所以就有一个手段, 对数据进行分片, 将数据划分到不同的实例之上.
>比如说需要保存 25 GB 的数据, 如果五个实例, 那么每个节点就只需要保存五个节点即可.
>对 Redis 进行切片属于 一个横向的拓展,横向的拓展比纵向 (扩大单个实例的内存)
>原理
>	根据 key, 按照一个算法计算出来一个值, 然后让这个值对 16383 取余, 从 0~16383 每个都是一个槽.
>	然后针对于不同的实例, 我们分配不同的槽, 比如说平均分配, 或者是按照不同实例的大小分配不同数量的槽, 当然必须把所有的槽都分配好.
>	也就是说不同的数据分配在不同的实例中, 并且如果 Redis 中集群增加或者减少实例, 会进行重新分配哈希槽
>问题 1: 既然不同的实例存储不同的数据
>	后端可以把槽的划分情况发给客户端, 前端保存信息, 然后再发送的时候再根据槽来传递数据?
>	重定向机制:
>		上一种方案可能有一种问题, 就是槽的信息可能会在集群改变之后失效.
>		重定向机制, 允许我们往任意一个实例发送请求, 如果不在, 会返回一个 MOVED 命令, 返回这个值所在的槽和 IP 地址, 经过这样的一次重定向, 客户端根据传来的 ID 重新请求
>重要: 如果集群发生变化, 要不要去迁移数据

#### 扩容很麻烦，如何解决呢?
>在数量很小的情况下，例如两三个，这个时候，扩容两倍是比较好的。因为 Hash 取模的特点是，当%2 或者%4，其实只会有 50%移动。

### 为什么要读写分离呢?
>不进行读写分离, 如果对一个数据修改了三次, 但是发送到了三个不同的实例上去了, 那么会发生一个问题, 就是现在的副本数据不一致了, 这就出现了一个问题---数据不一致性.


### 如果在主从库数据同步的时候网络断了会怎么办
>如果全量复制中途断开了,那么就会采用增量复制的方式继续同步,这里即将断开之后,主库中收到的命令同步给从库. (为什么不继续全量了, 因为全量复制本身就是比较慢的, 即使是 RDB, 相当于 Redis 的高速, 同步比较慢了, 如果又继续全量, 反而还更容易出问题. 因为上一次没有传过去, 网络很可能有问题)
>下面的很重要 [[06数据同步：主从库如何实现数据一致？_一手IT课程资源+微信2268731.pdf]]
>这是一个环形的缓冲区, 主库自己写到的位置, 从库会记录自己已经读到的位置, 我们用偏移量来表示主库写了多少, 从库的偏移量代表读了多少.
>注意啦: 因为是一个环形缓冲区, 写满之后会覆盖, 所以有个问题就是, 从库读取速度慢, 就可能导致之前的操作被覆盖了, 导致数据不一致. 这种情况下需要跳转 repl_backlog_size 参数

### 增量同步 
> 当从库发生断开重连之后, 会使用增量同步
>主库持有一个环形缓冲池, 能够记录一定数量的命令, 主库在接收到命令的同时不断写入, 写入之后呢, 移动写指针.
>因为同步的时候, 从库会一直记录自己读到的位置, 然后断开重连之后, 发送自己上次读到的位置, 然后开始给从库进行增量的传递数据.
>但是可能存在一种现象, 就是从库读取速度慢, 并且主库是环形缓冲池, 可能就有一种现象, 缓冲被覆盖了,==导致主从库数据不一致性问题==
![Pasted image 20230301200704.png](/img/user/zob_attach/Pasted%20image%2020230301200704.png)


### 主从库同步的流程
![Pasted image 20230226223018.png](/img/user/zob_attach/Pasted%20image%2020230226223018.png)
>主实例和从实例链接之后, 就开始触发一次全量同步, 主实例 fork 一个子进程, 然后生成 RDB 文件, 然后发送给从实例.==发送数据的时候, 主库是不会被阻塞的==
>从库接收到数据的时候,先清空当前数据库 (因为在连接之前是可能存在其他数据的), 然后加载 RDB 文件.
>然后当**主库**发送过 RDB 文件之后, 会使用一个专门的 replication buffer 来保存数据, 然后之后主库每进行一次写操作, 就会把这个操作写到 replication buffer 中, 也就是通过增量同步的方式来进行数据同步.
>==如果子节点过多的情况下, 可能会导致主库压力非常大, 因为其都需要 fork 一个子线程来生成 RDB 文件==
>	所以就存在一种架构, 就是, 主节点下连接少量的从节点, 也就是说主节点只需要把数据同步给他的几个从节点即可, 其他从节点就交给主节点下的从节点来进行复制了.==主--从--从架构==
>**注意: 假如期间发生了中断, 就会进行断点续传,**

### 为什么全量复制使用 RDB 不使用 AOF 的原因
>RDB 文件是经过压缩后的二进制数据, 文件很小.
>而 AOF 记录的是每一次的写操作命令, 写操作越多, 文件越大, 其中可能还有很多冗余操作, 虽然 [[2 知识库/1 数据库/Redis/索引笔记/📑 Redis--索引笔记--Redis面试题#AOF重写原理\|#AOF重写原理]] 会让 AOF 冗余少一点.
>AOF 大, 自然网络传输是比较耗时的. 还有个很重要的原因, 就是 RDB 是一种快照, 即某个瞬间的快照, 而 AOF 是命令, 逐行执行命令, 效率是很低的, 我觉得这和追求极致高可用的 Redis 不想看见的.==这是不使用 AOF 的原因==

### 你知道主从复制风暴吗?
>当多个从节点都同时从主节点复制的时候, 会导致主节点压力过大!!!
![Pasted image 20230428200519.png](/img/user/zob_attach/Pasted%20image%2020230428200519.png)


### 哨兵机制
[[07哨兵机制：主库挂了，如何不间断服务？_一手IT课程资源+微信2268731.pdf]]
>哨兵机制的主要任务就是: 监控, 选主, 和通知
>主要原理就是周期性的给所有的主从库发送 PING 命令, 类似于 Nacos 注册中心的心跳检测, 如果没有在规定时间内响应哨兵的命令, 那么久标记为下线状态 
>即假如主库没有在规定时间内响应哨兵的 Ping 命令, 哨兵就会判断主库下线, 然后开始切换主库的流程.
>哨兵机制选举出一个新的主节点, 然后通知所有的其他节点来执行 replicaof 和新主库同步.

^a 5 f 6 f 2

#### 哨兵机制基于 Raft 的思考
> [[分布式协议#Raft 协议\|分布式协议#Raft 协议]]
> 对于 Raft, 三种节点;
> 哨兵机制维护着三个节点, 属于对 Raft 的职责抽离, 原先是三个节点, Follower, Candidate 和 leader ,节点之间进行选举, 而哨兵机制则是把 <**选举**> 和 <**心跳检测**> 纳入了其范围, 节点只需要接收命令即可.
> 哨兵检测所有节点的心跳, 然后从节点 <**没有心跳**>就直接"火化", 如果是主节点, 则采用  <**投票**>, 都认为都死了, 才拉去"火化".
> 	如果主节点火化了, 就需要完成选举 [[2 知识库/1 数据库/Redis/索引笔记/📑 Redis--索引笔记--Redis面试题#^a5f6f2\|#^a5f6f2]]   ,然后让其他节点变成该节点的从节点

#### 如何判断下线
>因为哨兵回定期的 PING，所以说能够检测到服务的下线，如果从节点下线，直接标记就好了．但是主节点因为比较重要, 可能不能直接妄下断论, 就需要检测是否误判, 比如说因为此时网络拥塞了, 网络压力大等等.
>所以说对于让主节点进行下线, 需要让多数的哨兵都认为这个节点断开连接了才行.

#### 哨兵集群判断节点下线
>因为一个哨兵在判断主节点的可用性上是不可靠的, 可能会发生误判的现象, 所以就需要哨兵集群来判断主库是否下线, 少数服从多数, 才能让主库进行下线

#### 如果哨兵掉线了
>哨兵之间是可以相互发现的, 基于的是其发布定于机制,



#### 主节点的选取
>因为读写分离, 主节点需要进行写操作以及大量的复制操作, 所以说最重要的就是保证选出来的主节点一定要是可靠的.
>主要判断的就是该节点断开连接的次数, 这叫==筛选==
>然后就是给其他的从库打分, 比如说和主库同步程度最近的从库得分搞, 我们设置的优先级参数大的高.
>关键点: 如果判断和主库同步程度的高低?
>	还记得在主从复制中的偏移量吗, 主从库都维护一个环形缓冲池, 主从库都有一个偏移量,



### 子节点还能有子节点吗
>可以的, 这是一种 Redis 的架构, 因为如果是一个主节点, 那么会有一个问题, 就是如果主节点的节点很多, 那么在进行主从复制的时候可能主节点的压力就会非常大了!!!

### 缓存问题

#### 系统在某个时刻发生了访问量剧增 (热点新闻), 造成数据库压力
>增加一层 Redis 缓存层, 在所有的 Redis 节点上缓存热点 Key, 如果是像这种短期的少量热点新闻, 直接把整个新闻放到 Redis 中. 如果常见中这种 BigKey 很多, 那么就需要注意了, 防止 BigKey 占用大量内存了.

